{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Act 1: Data-centric workflows\n",
        "\n",
        "This notebook is Act 1 of 4 in the Building Multimodal AI Workflows with Pixeltable workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Notebook Segment**\n",
        "\n",
        "In this act, we'll:\n",
        "- Create a video table & insert media\n",
        "- Add computations\n",
        "- Write a query\n",
        "- Detect scene boundaries in the video\n",
        "\n",
        "**Documentation:** TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print pixeltable version\n",
        "try:\n",
        "    print(f\"Pixeltable version: {pxt.__version__}\")\n",
        "except AttributeError:\n",
        "    from importlib.metadata import version\n",
        "    print(f\"Pixeltable version: {version('pixeltable')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 01 - Create a video table & insert media\n",
        "\n",
        "üñáÔ∏è Links to docs:\n",
        "\n",
        "- Media types\n",
        "- Tables\n",
        "- Inserts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: delete this chunk\n",
        "pxt.list_tables()\n",
        "pxt.drop_table('chess_vids', force=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by creating a fresh Pixeltable with a single column of type `pxt.Video`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = pxt.create_table(\n",
        "    'chess_vids',\n",
        "    schema={'video': pxt.Video},\n",
        "    if_exists='replace_force'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course, the table is empty to start, but the schema is there:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll start with a single video and build up our video processing pipeline using this table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.insert([{'video': 'source/queens-gambit.mp4'}])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the video we just inserted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### More to explore\n",
        "\n",
        "More media types\n",
        "\n",
        "More on tables and table operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 02 - Add computations\n",
        "\n",
        "üñáÔ∏è Links to docs:\n",
        "\n",
        "- Computed columns\n",
        "- Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll start with our first computed column. Here, we'll use a built-in Pixeltable function for getting the duration of a video file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.add_computed_column(duration=t.video.get_duration())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check out the new table schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the new values in the table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we added that value as a computed column. This means a few things:\n",
        "1. That value is now in our persistent storage - not just in memory for this Python session\n",
        "2. For any new rows that are inserted, Pixeltable will compute the duration and fill in that cell\n",
        "3. We can use that value in any future computations, and Pixeltable will orchestrate those to happen in the right sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### More to explore\n",
        "\n",
        "We just covered computed columns, learn more..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 03 - Write a query\n",
        "\n",
        "üñáÔ∏è Links to docs:\n",
        "\n",
        "- Queries & expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But, let's say we don't want to commit a value to storage - we just want to explore and experiment. We can do that too, with queries using the `select()` and `collect()` combination in Pixeltable. Again, we'll use a built-in Pixletable function for videos to extract a single frame with a timestamp. Recall that our video was 377 seconds long, so you can re-run this cell over and over again to pull out any frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use select() to query your table\n",
        "# here, try changing the timestamp (between 0 and the duration of the video)\n",
        "t.select(t.video, t.video.extract_frame(timestamp=75)).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take another look at our table schema. You should see that we have only added one new column here, since we extracted the frame inside a query. The \"computed with\" metadata is your clue that this is a value derived from the video input, and it is the start of using Pixeltable for orchestrating your media transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### More to explore\n",
        "\n",
        "What else is similar to `extract_frame()`\n",
        "\n",
        "Video UDFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 04 - Scene detection\n",
        "\n",
        "üñáÔ∏è Links to docs:\n",
        "\n",
        "- Scene detection in Pixeltable\n",
        "- PySceneDetect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Media data can be hard to work with because (a) files are big and (b) many of your normal tricks for slicing and dicing data with static values won't work reliably across media types and content. Best practices for working with media data start with content-aware transformations. \n",
        "\n",
        "We'll use Pixeltable's built-in integration with PySceneDetect for smart scene detection. It detects breaks in-between content, not only when the video fades to black (although a threshold mode is available as well for those cases). \n",
        "\n",
        "This cell takes about 1-2 minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.add_computed_column(\n",
        "    scenes=t.video.scene_detect_content(fps=10),\n",
        "    if_exists='replace'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because this is a computed column, the computations now persist in the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can view the output for the detected scenes, which is a single cell with a JSON structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.select(t.scenes).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How can we examine the output from the scene detection model? The best way is to create a view on top of our video table. This view will then update any time the base table changes, keeping everything in sync as we work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<aside>\n",
        "\n",
        "### ü§ø **Technical Deep Dive** (5 min)\n",
        "\n",
        "Persistent storage & why it matters for experimentation\n",
        "\n",
        "- Database vs. in-memory processing\n",
        "- Don't recompute expensive operations after kernel restart\n",
        "- Demo: clear your notebook, restart kernel, and use `get_table()`\n",
        "- *Links to: Database concepts docs*\n",
        "</aside>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trust us! Clear all your outputs, restart your kernels, then run this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "pxt.list_tables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Any of these tables are \"gettable\" because Pixeltable persistently stores all of our outputs. So let's get the table we started with named `chess_vids` and assign it a variable `v` so we can pick up where we left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "v = pxt.get_table('chess_vids')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a query and collect to see the contents. Luckily, we don't need to re-run scene detection in this new session because the output is stored in our table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "v.select(v.video, v.scenes).collect()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
